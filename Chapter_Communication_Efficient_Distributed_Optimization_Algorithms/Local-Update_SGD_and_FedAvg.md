# 6.2 本地-更新SGD和FedAvg

在本节中，我们首先讨论本地更新SGD及其变体。FedAvg算法是联合学习的核心，它是本地更新SGD的扩展。我们讨论了FedAvg是如何建立在本地更新SGD之上的，以及用于处理联合学习中数据和计算异质性的各种策略。

## 6.2.1 Local-Update SGD及其变体

同步分布式SGD。在数据中心设置中，训练数据集D被洗牌并平均分配到m个工作节点。训练机器学习模型的标准方法是使用同步分布式SGD[11]，其中梯度由工人计算，然后由中央参数服务器汇总。在同步SGD的每个迭代t中，工作者从参数服务器中提取模型的当前版本xt。每个工作者i使用从本地数据集Di中抽取的B个样本的小批量随机梯度gi(x)=�ξ∈Bf (x; ξ)计算一个小批量随机梯度。然后，参数服务器收集来自所有工作者的梯度，并按以下方式更新模型参数
$$\bm{x}_{t+1} = \bm{x}_{t} - \frac{\eta}{m}\sum_{i=1}^{m}g_{i}(\bm{x})$$
随着工作器数量m的增加，同步SGD的误差与迭代收敛性得到改善。然而，由于工作器的局部梯度计算时间存在差异，等待所有工作器完成梯度计算的时间也会增加。为了提高工作器数量的可扩展性，[13, 15, 28, 29, 56, 58]中提出了同步SGD的抗滞后变体，进行异步梯度聚合。