# 通信效率高的分布式优化算法

在联邦学习中，连接边缘各方和中央聚合器的通信链路有时是有带宽限制的，而且会有很高的网络延迟。因此，急需设计和部署具有通信效率的分布式训练算法。在本章中，我们将回顾两种正交的具有通信效率的分布式随机梯度下降（SGD）方法：（1）本地更新的随机梯度下降（SGD），客户端进行多个本地模型更新，并定期汇总；（2）梯度压缩和稀疏化方法，以减少每次更新传输的比特数。在这两种方法中，误差收敛与迭代次数和通信效率之间存在着权衡。