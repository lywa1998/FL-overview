\chapter{联邦学习中的个性化}

\section*{摘要}
典型的联邦学习（FL)问题的表述需要学习一个适合所有各方的单一模型，同时禁止各方与聚合者分享他们的数据。然而，可能不可能学习一个适合所有各方的共同的单一模型。例如，考虑一个句子完成问题："我住在......的州"。答案显然取决于当事人，这里没有一个单一的模型是合适的。为了处理这种情况，最近的文献中提出了各种人格化策略。特别是，这个问题似乎与元学习有密切联系。我们回顾了最近的FL个性化技术，将其分为八组，并总结了三种策略和相应的数据集，以作为联合学习中个性化的基准。我们对联合学习中个性化的统计挑战进行了概述。在高层次上，个性化导致了模型复杂性的增加，这反过来又增加了联合学习任务的难度。我们研究了什么时候过多的个性化会阻碍个性化联合学习的标准方法学习各方的共同部分，并提出了克服此类问题的替代方法。

\section{导言}
集中式联合学习旨在从各方的数据中学习一个全局模型，同时保持他们的本地数据的私密性和对其个人机器的本地化。这个全局模型的优点是利用了所有各方的数据，因此对各方的测试数据具有更好的概括性。然而，在实际场景中，个别当事方的数据集往往是异质的（非IID），从而使一个全局模型的性能对某些当事方来说是次优的。另一方面，如果每一方都在他们的本地数据上训练一个本地模型，他们会在类似于测试时预期的数据分布上进行训练，但由于本地一方可用数据的匮乏，可能无法进行泛化。个性化联合学习的目的是学习一个具有全局模型的泛化能力的模型，但也能在每一方的特定数据分布上表现良好。

为了说明个性化的需要，考虑在联合学习环境中学习的语言模型的情况[10]：如果我们使用一个全局模型来预测提示的下一个词： "我住在......州"，全局模型将为每一方预测相同的标记（州名），而不考虑他们的本地数据分布。因此，虽然全局模型可能能够很好地学习语言的一般语义，但它却不能对个别当事人进行个性化处理。

除了上述定性的例子外，我们还可以从数量上证明个性化的必要性。我们使用MNIST数据集建立了我们的实验，该数据集被划分为100方。我们使用具有不同浓度参数（$α$）的Dirichlet分布[64]，以异质的方式在这些当事人之间分配数据。我们在两种情况下训练一个2层全连接网络，以衡量各方从参与联合学习中获得的好处。在第一种情况下，我们为100个党派中的每一个人训练一个单独的网络，只使用党派自己的数据训练10个历时，并测量这些单独网络在各自党派的测试数据（$\text{Acc}_{i}^{\text{local}}$）上的性能。在第二种情况下，所有100个党派都参与到使用联邦平均法（FedAvg）[39]训练一个全局模型，进行100个通信回合，我们测量这个全局模型在每个党派的测试数据上的性能（$\text{Acc}_{i}^{\text{global}}$）。图4.1显示了在不同的数据异质性水平下，每一方的全局模型和局部模型（$\text{Acc}_{i}^{\text{global}} - \text{Acc}_{i}^{\text{local}}$）的性能差异柱状图。从图中可以看出，全局模型对参与其训练的每一方都没有好处，当数据的非IID特征更严重（$\alpha$值更小）时，这种现象就更明显了。这个实验强调了在各方的本地数据分布上对全局模型进行个性化处理的必要性，以确保每一方都能从其参与的学习设置中获益。

在这一章中，我们回顾了在联合学习文献中提出的不同的个性化技术，并讨论了联合学习和一阶元学习[18]之间的联系。我们还研究了联合学习中个性化的统计限制。特别是，我们表明个性化在一定程度上提高了特定方的性能。在这一点之后，在问题中增加更多的当事方并不能导致性能的改善。

\section{迈向个性化的第一步}
在这一节中，我们将考察一种结合了联合学习和个性化的基本技术，并探讨为什么这种技术是个性化任务的一个强有力的基线。

\subsection{微调全局模型实现个性化}
使用联合学习学到的全局模型进行个性化的一个直接方法是在本地数据上进一步训练它。这种方法允许我们通过对全局模型进行本地更新的数量来控制 通过对全局模型进行本地更新的数量来控制个性化程度--零本地更新可以保留全局模型，而随着本地更新数量的增加，模型对本地数据变得更加个性化。

虽然这种技术可能看起来很简单，但它是人称化任务的一个强有力的基线。我们在第4节介绍的实验中研究了这种微调方法。4.1和图4.1。我们通过在本地数据上进行1次微调，将在100个当事人身上学到的全局模型个性化，然后在当事人的本地测试数据上测量这个微调模型的性能。通过这个实验的结果可以看出，与本地模型相比，这种简单的微调技术大大地提高了全局模型的性能。对于异质性的极端情况，这种方法提高了相当多的当事方的性能，也没有对异质性不太严重的情况下的性能产生负面影响。我们现在旨在了解这种微调方法的强大性能背后的原因。

\subsection{作为一阶元学习方法的联合平均法}
在这一节中，我们试图理解使用联合平均法学习的全局模型进行微调的有效性背后的原因。我们复制了Jiang等人[29]的推导，表明联合平均法的更新是联合SGD更新和一阶MAML（FOMAML）更新的组合。

什么是元学习和MAML？
传统的机器学习方法旨在学习在给定任务上表现最好的参数，而元学习或学习学习[55- 57, 59]旨在学习可以快速适应新任务的参数。模型不可知元学习（MAML）[18]是最流行的元学习方法之一：它的目标是找到可以在少数梯度更新中适应新任务的模型参数。然而，为了实现这一目标，MAML的目标需要计算二阶导数，这在计算上是很昂贵的。一阶MAML（FOMAML）[43]通过只考虑一阶导数来接近MAML的目标，从而减少MAML的计算需求。参见第4.3.5节。4.3.5节进一步讨论了元学习和相关的联合学习个性化策略。

我们通过定义FedSGD的更新来开始分析（公式（\ref{eq:4-1}））。FedSGD的操作方式是对$N$个缔约方中的每一个采取单一的梯度步骤，将这些梯度传回给聚合器，然后聚合这些梯度来更新全局模型。我们用$\nabla_{k}^{i}$来表示第$i$方的第$k$步梯度。
\begin{align}\label{eq:4-1}
	\nabla_{\text{FedSGD}} = \frac{1}{N}\sum_{i=1}^{N} \frac{\partial \mathcal{L}_{i}(\theta)}{\partial \theta} = \frac{1}{N}\sum_{i=1}^{N} \nabla_{1}^{i}
\end{align}
其中$\theta$为模型参数（如神经网络权重），$\mathcal{L}_{i}(\theta)$为$i$方的损失。接下来，我们以类似的方式推导出MAML和一阶MAML[18]的更新。假设$\theta_{K}^{i}$是第$i$方的个性化模型，是在以$\beta$为学习率的损失梯度上走了$K$步后得到的：
\begin{align}\label{eq:4-2}
	\theta_{K}^{i} = \theta - \beta \sum_{j=1}^{K} \frac{\partial \mathcal{L}_{i}(\theta_{j}^{i})}{\partial \theta}
\end{align}

然后，MAML更新被定义为个性化模型$\theta_{K}^{i}$相对于初始参数$\theta$的梯度，在$N$个当事方中平均。不幸的是，这种计算需要高阶导数，即使对$K=1$来说也很昂贵。FOMAML忽略了高阶导数，只使用一阶梯度：
\begin{align}\label{eq:4-3}
	\nabla_{\text{FOMAML}}(K) = \frac{1}{N} \sum_{i=1}^{N} \frac{\partial \mathcal{L}_{i}(\theta_{K}^{i})}{\partial \theta} = \frac{1}{N} \sum_{i=1}^{N} \nabla_{k+1}^{i}
\end{align}

在计算了FedSGD和FOMAML的更新后，我们现在来看看Federated Averaging（FedAvg）的更新。FedAvg的更新是各方更新的平均值，是局部梯度更新$\nabla_{j}^{i}$的总和：
\begin{align}
	\nabla_{\text{FedAVG}} = \frac{1}{N} \sum_{i=1}^{N} \sum_{j=1}^{K \nabla_{j}^{i} = \frac{1}{N} \sum_{i=1}^{N} (\nabla_{1} + \sum_{j=1}^{K-1} \nabla_{j+1}^{i}) \label{eq:4-4} \\
		= \frac{1}{N} \sum_{i=1}^{N} \nabla_{1} + \sum_{j=1}^{K-1} \frac{1}{N} \sum_{i=1}^{N} \nabla_{j+1}^{i} \label{eq:4-5}
\end{align}

重新排列这些条款，我们可以得出FedAvg、FedSGD和FOMAML的更新之间的关系：
\begin{align}\label{eq:4-6}
	\nabla_{\text{FedAvg}} = \nabla_{\text{FedSGD}} + \sum_{j=1}^{K-1} \nabla_{\text{FOMAML}}(j)
\end{align}

在每次通信之前，FedAvg中$1$个梯度更新（$K=1$）的FedAvg更新根据公式（ \ref{eq:4-6}）减少到FedSGD设置。增加梯度更新的数量会逐步增加更新中的FOMAML部分。根据Jiang等人[29]的研究，用$K=1$训练的模型很难个性化，而增加$K$可以增加模型的个性化能力，直到某一点，超过这一点，初始模型的性能就变得不稳定。

\section{个性化策略}
近年来，联合学习环境下的个人化在研究界获得了相当大的兴趣。在这一节中，我们研究了针对这一问题提出的各种技术，并将它们分为8大类。表4.1中总结了分类标准以及属于各自标准的方法。在下面的小节中，我们将深入研究表中定义的每个标准，并研究其优势和劣势。

\subsection{客户（方）集群}
联合学习中个性化的核心前提是，由于各方数据的非IID异质性分布，一个全局模型可能无法适用于所有各方。用于个性化的客户（当事方）聚类技术在一个共同的假设下运作：在系统中存在的$N$个当事方中，有$K<N$的不同数据分布。这个假设使这些技术能够将各方聚成$K$个集群，以缓解非IID数据分布条件，并为$K$个集群中的每一个学习一个共同的全局模型。因此，在这种表述下，个性化问题又被细分为两个子问题：（1）定义一个聚类假设，将各方聚在一起；（2）为每个定义的聚类汇总并学习一个模型。

集群联合学习（CFL）[47]假设存在一个分区$\mathcal{C} = \left\{ c_{1}, \cdots, c_{K} \right\}, \cup_{k=1}^{K} c_{k} = \left\{ 1, \cdots, N \right\}$，这样，每一个缔约方的子集$c_{k} \in \mathcal{C}$都满足传统的联合学习假设，即全局模型同时对所有缔约方的数据分布进行风险最小化。然而，CFL并不是一次就能识别出完整的当事方聚类$\mathcal{C}$，而是递归地将当事方双分到聚类中，直到所有的聚类都被识别出来。该算法通过训练局部模型进行，直到收敛到一定限度。然后，这些单独的当事方模型被汇总，并检查全局模型的一致性，即全局模型在多大程度上使每一方的风险最小。如果全局模型符合各方的某个停止标准，CFL就会终止。否则，各方被划分为两个子群，CFL在每个子群上被递归执行。由于双分区方法是递归地工作的、集群的数量$K$不需要事先知道。此外，由于聚类机制是在聚合器上实现的，各方并不承担该方法的计算负担。相反，聚合器凭借其通常比各方更强的计算能力，可以减少聚类的开销。

3S-聚类[19]也制定了与CFL[47]类似的问题，但它的目的不是递归的双分区方，而是在聚合器上一次性找到$K$个集群。一旦本地模型被训练好并传达给聚合器、3S-聚类执行一种聚类方法--通常情况下，KMeans可行，但也可以采用其他的聚类方法，如原始论文中所示，他们研究这种方法主要是为了在聚合器上进行byzantine-robust分布式优化，以寻找$K$个聚类。然而，这种方法仅限于凸目标，因此不适用于非凸目标，如深度神经网络的情况。

前面提到的两种方法使用聚合器进行聚会聚类，而这一类的另外两种方法，IFCA[20]和HypCluster[36]则利用聚会来确定自己的聚类成员资格（图4.2）。这两种方法彼此相当相似，通过聚合器维护K个集群中心和相关的模型参数来操作。在每一轮，聚合器将集群参数广播给每一方，而每一方则通过选择实现最低损失值的参数来估计其集群身份。然后，这些集群中心被用作本地模型的初始化器，在本地数据上进行微调，并与集群身份一起发回给聚合器进行聚合。
聚合器然后根据模型的集群成员资格聚合模型，整个过程重复进行。

\subsection{客户背景介绍}
学习用户特定的情境特征或嵌入已被广泛用于改善与联合学习无关的问题中模型的个性化[1, 22, 27, 38, 58]。客户端情境化利用了学习用户嵌入的相同方法来完成联合学习中的个性化任务。这种方法背后的原理是，每一方的嵌入捕捉了特定一方的特征，并作为全局模型的指标，利用这种背景来调整它对特定一方的预测。

联合协作过滤（FCF）[2]提出了一个基于协作过滤[48]的推荐系统，以联合的方式学习。协同过滤通过用户-物品交互矩阵$\bm{R} \in \mathbb{R}^{N \times M}$作为用户因素矩阵$\bm{X} \in \mathbb{R}^{K \times N}$和物品因素矩阵$\bm{Y} \in \mathbb{R}^{K \times M}$的线性组合来模拟$N$个用户和$M$个物品之间的交互。
\begin{align}\label{eq:4-7}
	\bm{R} = \bm{X}^{T}\bm{Y}
\end{align}

在FCF算法的每个迭代中，聚合器将物品因素矩阵$\bm{Y}$发送给每一方，而每一方又使用他们的本地数据来更新用户因素矩阵$\bm{X}$和物品因素矩阵$\bm{Y}$。更新的物品因素矩阵被送回聚合器进行聚合，而用户因素矩阵在每一方都是保密的。这允许每一方学习自己的用户因素矩阵集，同时利用各方的项目因素信息。在比较FCF和标准协同过滤的实验中，FCF被证明在多个推荐性能指标和多个推荐数据集上与标准协同过滤的性能接近。

虽然FCF是专门针对协同过滤的，但FURL[5]通过(a)定义私有和联合参数以及(b)指定独立的本地训练约束和独立的聚合约束来概括这种方法。独立的本地训练约束规定，本地各方使用的损失函数与其他各方的私有参数无关，而独立的聚合约束规定，全局聚合步骤与各方的私有参数无关。当这些条件得到满足时，FURL保证了将参数分成私有参数和联合参数不会造成模型质量损失。

图4.3a显示了FURL在文档分类任务中的应用。这里，用户嵌入对每一方都是私有的，而BiLSTM和MLP的参数是所有用户共享的联合参数。每一方联合训练私有参数和联合参数，但只与聚合器分享联合参数以进行聚合。在实验中，通过FURL实现的个性化被证明可以显著提高文档分类任务的性能。

然而，通过FURL实现个性化，有几个缺点。首先，使用FURL需要将私人参数纳入建模，这可能需要对网络结构进行修改。随后，将私人参数纳入模型增加了需要学习的参数数量，鉴于当事方数据的匮乏，这可能会使任务更加困难。最后，FURL技术对于新的政党来说存在一个冷启动问题。由于私有参数是针对每一方的，新加入框架的各方需要首先训练他们的私有参数，然后才能利用个性化的力量，在此之前可能会遭受性能下降的影响。

\subsection{数据增强}
数据增强技术已被用于标准的机器学习问题，以缓解类不平衡、非IID数据集的问题，或人为地增加其他较低大小的数据集。这些技术包括从过度采样代表性不足的类样本[8]到训练GANs来生成增强的数据样本[37]。对这一领域感兴趣的读者应该参考关于数据增强技术的调查，以了解这一领域的情况[40, 52]。

由于联合学习也受到各方数据匮乏的影响，而全球范围内有大量的数据，因此很自然地会问，全球数据（跨越所有各方的数据）是否可以用来提高某一方的性能。本着同样的精神，人们提出了一些方法，要么在全球范围内共享少量的数据，以帮助提高各方的性能[66]，要么在本地模型之外训练生成对抗网络（GAN）以增强数据样本[28]。

一种直接的增强数据的方法是收集所有各方的数据子集，创建一个全球共享的数据集，每一方都可以用它来增强他们的本地数据集。DAPPER[36]和全球数据共享[66]方法就属于这个类别。这两种方法都利用一个表明全球数据分布的全局数据集DG。全局数据共享方法建议通过共享一个在全局数据集上训练的热身模型，以及数据集的一个随机子集（αDG）给每一方来初始化联合学习过程。每一方用聚合器提供的数据集增加其本地数据集，以训练其本地模型，然后将其传送回聚合器进行聚合。图4.3b显示了这个过程的说明。

另一方面，DAPPER[36]不是直接用全局数据集来增加本地数据集，而是优化目标：
\begin{align}\label{eq:4-8}
	\lambda D_{\text{party}} + (1 - \lambda)D_{G}
\end{align}

每一方在每个优化步骤中，都以$\lambda$的概率选择本地数据集$D_{\text{party}}$，以$(1 - \lambda)$的概率选择全局数据集$D_{G}$进行优化。 其余的优化和聚合步骤保持不变。

DAPPER和全球数据共享方法都显示出比没有个性化训练的模型有明显的改进，但它们需要将各方的数据转移到全球聚合器和其他各方。将当事人的数据转移到他们的机器之外，违反了联合学习的隐私保证，因此这些方法在实践中可能无法直接实现。

XorMixup[51]旨在规避与转环方数据有关的隐私问题，同时仍然利用数据增强的个性化能力。它建议使用一个XOR编码方案来混淆上传到聚合器的数据样本。实施XorMixup的每一方首先从两个不同的类别标签中选择数据样本，然后使用两者的XOR创建一个编码的数据样本。每一方都将这种编码样本上传到聚合器，聚合器使用来自指定类标签的单独数据样本对其进行解码，并使用这些解码样本来训练模型。这些编码样本被证明与原始数据样本有很高的不相似性，而且在非IID条件下，模型的性能也有改善。

\subsection{蒸馏}
在联合学习的一般表述下，当聚合器将一个模型发送给一方时，它将该模型作为起点，在本地数据上进行训练。通过蒸馏实现的个性化采取了不同的方法来解决这个问题。基于蒸馏的方法不是使用中心模型参数作为起点，而是使用知识蒸馏[21,24]在其他模型之间转移知识，而不明确复制参数。利用蒸馏而不是复制模型参数的一个关键优势是，模型架构不需要在各方和聚合器之间相同，框架就能发挥作用。例如，各方可以选择更适合他们的数据的模型架构和硬件约束。联合相互学习（FML）[50]和FedMD[34]是遵循这种方法的两个主要方法。

什么是知识蒸馏？
模型压缩[11]是指减少模型大小的任务，从而减少存储模型所需的内存，提高推理速度，同时保留原始神经网络中的信息。知识提炼[21, 24]是一种模型压缩技术，旨在将信息或知识从一个较大的网络有效地转移到一个较小的网络。在知识提炼中，有3个主要组成部分--教师网络、学生网络和知识。教师网络是编码知识的较大的模型，这些知识需要转移到通常规模较小的学生网络中。有几种方法可以定义要提炼的知识[21]--它可以是网络中某些层的输出（如基于反应和特征的知识），也可以是不同层或数据样本之间的关系（如基于关系的知识）。

FML在本地模型和全局模型之间采用双向提炼的方式。实施FML的各方维护一个本地模型，该模型在他们的数据上不断训练，而不与聚合器共享数据。在每一轮通信中，聚合器向每一方发送全局模型，该模型由该方通过全局和局部模型之间的双向知识蒸馏进行更新。相应的目标函数如下：
\begin{align}
	\mathcal{L}_{\text{local}} = \alpha \mathcal{L}_{\text{local}} + (1 - \alpha)D_{KL}(p_{\text{global}} || p_{\text{local}}) \label{eq:4-9} \\
	\mathcal{L}_{\text{global}} = \beta \mathcal{L}_{\text{global}} + (1 - \beta)D_{KL}(p_{\text{local}} || p_{\text{global}}) \label{eq:4-10}
\end{align}

由于FML中局部和全局模型之间的连接是通过输出概率的KL发散，而不像其他联合学习方法中通过参数复制，所以局部和全局模型的架构可以是不同的。FML的原始工作[50]进行了实验来证明这种效果。在不同的一方使用不同的网络架构，作者显示在这种设置下，比独立训练一个全局模型也有改善。

FedMD[34]也提出了一个类似于FML的使用distilla- tion的个性化表述。FedMD框架需要一个公共数据集，该数据集在各方和聚合器之间共享，同时还有各方维护的私人数据集。 该框架通过各方首先在公共数据集上训练模型，然后在各自的私有数据集上进行训练，然后将公共数据集中每个样本的等级分数传达给中央聚合器。所有各方的这些等级分数的汇总被用作目标分布，每一方使用蒸馏法学习。与FML类似，FedMD具有支持各方不同模型架构的优势。然而，FedMD需要一个大型的公共数据集，需要在各方之间共享，从而增加了各方和聚合器之间的通信成本。

\subsection{元学习方法}
当代机器学习模型被训练成在单一任务上表现良好。另一方面，元学习或 "学会学习"[25, 57, 59]的目的是学习可以快速适应新任务的模型，只需要少量的例子。有多种方法可以实现这一点--基于指标、基于模型和基于优化的方法[59]。在本节中，我们重点讨论基于优化的方法，它更适合我们的目的。基于优化的元学习技术旨在学习模型参数，这些参数可以在给定的少量例子和几个梯度更新内快速修改以适应新任务。模型不可知元学习（MAML）[18]是一种相当流行的方法，适用于任何可以用基于梯度的方法学习的模型。MAML不是训练模型参数以最小化给定任务上的损失，而是训练模型参数以最小化几个参数适应步骤后的任务上的损失。如果我们把每个任务看作是联合学习设置中的一方，我们可以在个性化的联合学习和元学习之间得出一个平行的结论。我们希望训练一个全局模型，作为聚会模型的一个很好的初始化器，使其能够快速适应，即个性化，以适应聚会数据的分布。在第4.2节中，我们回顾了在全球范围内的联系。4.2节中，我们回顾了天真的个性化基线（即FedAvg的微调）与元学习之间的联系。现在我们回顾一下最近的其他基于元学习的方法。

ARUBA[31]是一个将元学习与多任务学习技术相结合的框架，使元学习方法能够学习并利用任务的相似性来提高其性能。ARUBA背后的动机之一是，在元学习模型中，某些模型的权重作为特征提取器，不需要太多修改就可以在不同的任务中转移，而其他权重则变化很大。有了每个坐标的学习率，就可以根据参数在不同任务中的可转移性，以不同的速度进行调整。ARUBA在联合学习环境下对下一个字符预测任务进行测试时，与微调的FedAvg基线的性能相匹配，但没有对微调学习率进行额外的超参数优化。

FedMeta[9]--与ARUBA同时提出--将标准的元学习算法纳入联合学习设置。在这种设置下，聚合器的目的是保持一个初始化，使一方能够迅速适应其本地数据分布。当事人通过在本地执行元学习算法的内循环（支持数据的适应步骤）进行训练，并将外循环的梯度（查询数据）返回给聚合器，聚合器使用这些信息来更新其初始化。虽然FedMeta通过在当事人身上运行元学习步骤，同时在聚合器上聚合模型初始化，将元学习纳入了个性化，但Per-FedAvg[17]显示，这种表述在某些情况下可能表现不佳。相反，Per-FedAvg假设每一方将全局模型作为初始化，并就其自身的损失函数更新一个梯度步骤，将问题表述改变为如下（4.11）：
\begin{align}\label{eq:4-11}
	\min_{\theta} := \frac{1}{N} \sum_{i=1}^{N} \mathcal{L}_{i}(\theta - \alpha \nabla \mathcal{L}_{i}(\theta))
\end{align}

最后，FedPer[3]提出将全局模型分离成一个作为特征提取器的基础网络和一个个性化层。各方共同训练基础层和个性化层，但只与聚合器共享基础网络进行聚合。这允许系统使用来自多方的信息学习表征提取网络，同时学习针对每一方的个性化层。原文中没有明确探讨这种方法和元学习之间的联系，元学习文献中也有相关的工作，几乎没有内循环（ANIL）[45]，它提出将网络分离成主体和头部网络，在元学习的内循环中只让头部适应新任务。

\subsection{模型的混合}
在联合学习的标准表述中，本地模型是在本地数据上训练的，而全局模型则是将各方的信息汇总起来，建立一个全局模型。一方参与联合学习的主要动机是利用其他方的信息，与在本地训练模型相比，减少其概括误差。然而，在某些情况下，全局模型对联合学习系统中的某些当事方的表现比这些当事方在本地训练的单个模型要差[62]，例如，见图4.1的实验。这就促使了通过学习一个参数来混合全局和局部模型的想法，以最佳方式结合这两个模型。

FL+DE[44]使用专家混合技术[63]学习结合本地和全局模型的预测类别概率。每一方都保持一个在本地数据上训练的本地领域专家（DE）模型，同时也与其他各方合作建立一个全局模型。门控函数（$\alpha_{i}(x)$）--在最初的工作中被参数化为逻辑回归模型[44]--与联合学习设置一起学习，以最佳方式结合全局模型（$\hat{y}_{G}$）和本地领域专家（$\hat{y}_{i}$）的预测类概率。因此，门控函数在输入的条件下，学习两个模型之间的偏好区域。对一个给定的数据样本$x$的最终预测是两个模型的预测类别概率的凸组合：
\begin{align}
	\hat{y}_{i} = \alpha_{i}(x)\hat{y}_{G}(x) + (1 - \alpha_{i}(x)) \hat{y}_{\text{local}}(x) \label{eq:4-12} \\
	\alpha_{i}(x) = \sigma(w_{i}^{T}x + b_{i}) \label{eq:4-13}
\end{align}

MAPPER[36]和APFL[15]方法没有使用专家混合技术来组合输出概率，而是学习一个混合参数（$\alpha$）来优化组合局部和全局模型。在APFL中，虽然全局模型仍然像传统的联合学习那样被训练成在集合域上的经验风险最小化，但本地模型（$h_{\text{local}}$）被训练成也使用$\alpha$来纳入全局模型（$h_{g}$）的一部分（公式（4.14））。第$i$方的个性化模型是全局模型（$h_{g}$）和局部模型（$h_{\text{local}}$）的凸组合（公式（\ref{eq:4-15}））。
\begin{align}
	h_{\text{local}} = \arg \min_{h} \hat{\mathcal{L}}_{D_{i}} (\alpha_{i}h + (1-\alpha_{i})h_{g})	\label{eq:4-14} \\
	h_{\alpha_{i}} = \alpha_{i}h_{\text{local}} + (1 - \alpha_{i})h_{g}	\label{eq:4-15}
\end{align}

到目前为止，我们所研究的三种方法都保持了局部和全局模型。然而，这些模型都是为同一任务而训练的。LG-FedAvg[35]则提议将学习任务在本地和全局模型之间进行分叉--每一方都学习从原始数据中提取高级表征，而全局模型则在所有设备的这些表征（而不是原始数据）上操作。我们在图4.4中描述了一个图像分类任务的LG-FedAvg过程。在这里，局部模型被训练成从原始图像中提取高级表征，虽然全局模型是使用监督学习训练的，但局部模型可以自由选择技术来学习这些表征。如图4.4所示，可以使用监督预测任务（使用辅助模型将表征映射到预测）或无监督或半监督技术（子图（a）至（c））来学习这些表征。本地模型也可以通过针对受保护属性的对抗性训练来学习公平表征  (子图d)。这种分叉有几个好处： (a) 在表征而不是原始数据上操作全局模型，减少了全局模型的大小，从而减少了需要在聚合器和各方之间交流的参数和更新的数量，(b) 它允许本地各方根据其本地数据集的特点选择专门的编码器来提取表征，而不是使用一个通用的全局模型，(c) 它允许本地模型学习混淆受保护属性的公平表征，从而增强本地数据的隐私性。

\subsection{模型正则化}
在传统的监督式联合学习中，系统被优化为：
\begin{align}\label{eq:4-16}
	\min_{\theta} \left\{ \mathcal{L}(\theta) := \frac{1}{N} \sum_{i=1}^{N} \mathcal{L}_{i}(\theta) \right\}
\end{align}

这里，$N$是当事方的数量，$\theta$是模型参数，$\mathcal{L}_{i}(\theta)$表示第$i$方数据分布的损失。

另一方面，基于规则化的个性化技术对标准目标的规则化版本进行优化。Loopless Local Gradient Descent（L2GD）[23]、Federated Attentive Message Passing（FedAMP）[26]、pFedME[16]和Fed+[61]都是正则化技术的实例，主要区别在于它们对正则化目标的定义。

L2GD[23]将正则化目标定义为局部模型参数（$\theta_{i}$）与各方平均参数（$\bar{\theta}$）之差的L2准则，整个系统优化方程（\ref{eq:4-17}）和（\ref{eq:4-18}）中定义的目标。为了优化这一目标，L2GD提出了一种非均匀SGD方法，并对各方与聚合器之间所需的通信回合数进行收敛分析。该方法将目标视为一个2和问题，对$\nabla \mathcal{L}$或$\nabla \psi$进行采样以估计$\nabla F$，并定义了一个梯度的无偏估计器，如公式（\ref{eq:4-19}）。在每个时间步骤中，要么局部模型以$1-p$的概率采取局部梯度步骤，要么聚集器以$p$的概率将局部模型向平均方向移动。
\begin{align}
	\text{L2GD}: \min_{\theta_{1}, \cdots, \theta_{N}} \left\{ F(w) := \mathcal{L}(\theta) + \lambda \psi(\theta) \right\} \label{eq:4-17} \\
	\mathcal{L}(\theta) := \frac{1}{N} \sum_{i=1}^{N} \mathcal{L}_{i}(\theta_{i}), \psi(\theta) := \frac{1}{2N} \sum_{i=1}^{N} \|\theta_{i} - \bar{\theta}\|^{2} \label{eq:4-18} \\
	G(\theta) := \left\{
		\begin{matrix}
			\frac{\nabla \mathcal{L}(\theta)}{1 - p} \text{ 以 } 1 - p \text{ 的概率} \\
			\frac{\lambda \nabla \psi(\theta)}{p} \text{ 以 } p \text{ 的概率}
		\end{matrix}
	\right. \label{eq:4-19}
\end{align}

L2GD适用于凸型损失函数并提供保证，因此不能直接适用于神经网络模型中通常遇到的非凸型损失函数。

pFedMe[16]通过定义如下的目标，将个性化问题建模为一个双级优化问题：
\begin{align}
	\text{pFedMe}: \min_{\theta} \left\{ F(\theta) = \frac{1}{N} \sum_{i=1}^{N}F_{i}(\theta) \right\} \label{eq:4-20} \\
	F_{i}(\theta) = \min_{\theta_{i}} \left\{ \mathcal{L}_{i}(\theta_{i}) + \frac{\lambda}{2}\|\theta_{i} - \theta\|^{2} \right\} \label{eq:4-21}
\end{align}

这里，$\theta_{i}$是第$i$方的个性化模型，根据其本地数据分布进行训练，同时与内部层面的全局模型参数$\theta$保持一定的距离。然后，一方的最佳个性化模型被定义为
\begin{align}\label{eq:4-22}
	\hat{\theta}_{i}(\theta) := \text{prox}_{\mathcal{L}_{i} / \lambda}(\theta) = \arg \min_{\theta_{i}} \left\{ \mathcal{L}_{i}(\theta_{i}) + \frac{\lambda}{2} \|\theta_{i} - \theta\|^{2} \right\}
\end{align}

与FedAvg类似，实施pFedMe的系统在每一轮通信中向各方发送全局模型权重，并在一定数量的局部回合后利用各方返回的权重进行模型聚合。与FedAvg不同，当事人在本地最小化方程（\ref{eq:4-21}），这是一个双级优化问题。在每个局部回合，党首先解决方程（\ref{eq:4-22}），以找到最佳的个性化党的参数$\hat{\theta}_{i}(\theta_{i, r}^{t})$。这里，$\theta_{i, r}^{t}$是$i$方在全局回合$t$和局部回合$r$的局部模型，其中$\theta_{i, 0}^{t} = \theta^{t}$。此后，在外部层面上，一方利用梯度更新本地模型$\theta_{i, r}^{t}$，相对于$F_{i}$方程（\ref{eq:4-21}）。

FedAMP[26]为个性化提出了以下目标：
\begin{align}\label{eq:4-23}
	\min_{\theta} \left\{ \sum_{i=1}^{N} \mathcal{L}_{i}(\theta_{i}) + \lambda \sum_{i < j}^{N} A(\|\theta_{i} - \theta_{j}\|^{2}) \right\}
\end{align}

目标的第二部分定义了一个注意力诱导函数$A(\|\theta_{i} - \theta_{j}\|^{2})$，它以非线性的方式衡量各方参数之间的相似性，旨在改善各方之间的合作。注意力诱导函数可以采取任何形式；然而，在拟议的工作中，作者使用了负指数函数$A(\|\theta_{i} - \theta_{j}\|^{2}) = 1 - e^{-\|\theta_{i} - \theta_{j}\|^{2}/\sigma}$。为了优化目标，FedAMP采用了一种交替优化策略，首先通过从各方收集的权重在聚合器上优化$\sum_{i<j}^{N} A(\|\theta_{i} - \theta_{j}\|^{2})$，然后使用其本地数据集在相应各方优化$\mathcal{L}_{i}(\theta_{i})$。

Fed+[61]认为，稳健聚合可以更好地处理各方数据的异质性，并通过模型正则化的方法来适应个性化。Fed+引入了一个凸的惩罚函数$\phi$和常数$\alpha, \nu$，如下所示：
\begin{align}\label{eq:4-24}
	\min_{\theta, z, \bar{\theta}} \frac{1}{N} \left\{ F_{\nu, \alpha}(\theta, z, \bar{\theta}) = \sum_{i=1}^{N} \mathcal{L}_{i}(\theta_{i}) + \frac{\alpha}{2} \|\theta_{i} - z_{i}\|_{2}^{2} + \nu \phi (z_{i} - \bar{\theta}) \right\}
\end{align}
并提出了一个当前局部和全局模型的稳健组合，通过对$z_{i}$进行最小化（\ref{eq:4-24}），保持$\theta_{i}$和$\bar{\theta}$固定而得到。设置$\phi(\cdot) = \|\cdot\|_{2}$可以得到几何中位数的$\rho$-平滑近似值，这是一种稳健的聚合形式：
\begin{align*}
	z_{i} \leftarrow \bar{\theta} + \text{prox}_{\phi / \rho}(\theta_{i} - \bar{\theta}), \rho := \nu / \alpha \\
	z_{i} = (1 - \lambda_{i}) \theta_{i} + \lambda_{i}\bar{\theta}, \lambda_{i} := \min \left\{ 1, \rho / \|\theta_{i} - \bar{\theta}\|_{2} \right\}
\end{align*}
为了从$\left\{\theta_{i}\right\}$中计算出稳健的$\bar{\theta}$，聚合器运行以下两步迭代程序，初始化为$	\bar{\theta} = \theta_{\text{mean}} := \text{Mean}\left\{ \theta_{i} \right\}$，直到$\bar{\theta}$收敛：
\begin{align*}
	v_{i} \leftarrow \max \left\{ 0, 1 - (\rho / \|\theta_{i} - \bar{\theta}\|_{2}) \right\}(\theta_{i} - \bar{\theta}) \\
	\bar{\theta} \leftarrow \theta_{\text{mean}} - \text{Mean}\left\{ v_{i} \right\}
\end{align*}

\subsection{多任务学习}
传统的机器学习方法通常为单一任务优化一个模型。多任务学习（MTL）[4, 7, 54]扩展了这种传统的方法，以联合学习多个任务，从而利用任务之间的共同点和差异来潜在地提高单个任务的性能。由于这些方法可以学习非IID和不平衡数据集之间的关系，它们很适合应用于联合学习的环境[53]。对多任务学习感兴趣的读者应该参考以下调查论文[46, 65]，以获得该领域的概况。

虽然MTL方法在联合学习的背景下很有吸引力，但它们并没有考虑到框架中的通信挑战，如容错和散兵游勇。MOCHA[53]是第一个使用多任务学习的联合学习框架，它在训练中考虑了容错和散兵游勇。多任务学习方法通常将问题表述如下：
\begin{align}\label{eq:4-25}
	\min_{w, \Omega} \left\{ \sum_{i=1}^{N}\mathcal{L}_{i}(\theta_{i}) + R(\Omega) \right\}
\end{align}

这里，$N$是任务的总数，$\mathcal{L}_{i}(\theta_{i})$和$\theta_{i}$是任务$i$的损失函数和参数。矩阵$\Omega \in \mathbb{R}^{N \times N}$表示任务之间的关系，它要么是事先已知的，要么是在同时学习任务模型时估计的。MTL方法的不同之处在于他们对$R$的表述，即通过$\Omega$矩阵促进任务之间的适当结构。MOCHA在联合学习环境中使用目标的分布式原始-双重优化表述来优化这一目标。这使得它可以通过只要求一方的可用数据来更新本地模型参数，从而将各节点的计算分开。MOCHA显示了多任务学习方法在联合学习环境中的适用性，并且与在实验数据集上训练的全局和局部模型相比，表现出更好的性能。然而，它只为凸型模型设计，因此不适用于非凸型深度学习模型。

VIRTUAL（变异联合多任务学习）[14]通过使用变异推理方法将多任务学习框架扩展到非凸模型。给定$N$个当事方，每个当事方都有数据集$D_{i}$、局部模型参数$\theta_{i}$和中心模型参数$\theta$，VIRTUAL计算出后验分布
\begin{align}\label{eq:4-26}
	p(\theta, \theta_{1}, \cdots, \theta_{N} | D_{1:N}) \propto \frac{\prod_{i=1}^{N} p(\theta, \theta_{i} | D_{i})}{p(\theta)^{N-1}}
\end{align}

这种后验分布假定：（1）在给定聚合器和政党参数的情况下，政党数据是有条件独立的，$p(D_{1:N} | \theta, \theta_{1}, \cdots, \theta_{N}) = \prod_{i=1}^{N} p(D_{i} | \theta, \theta_{i})$和（2）先验的因子化为$p(\theta, \theta_{1}, \cdots, \theta_{N}) = p(\theta) \prod_{i=1}^{N}p(D_{i} | \theta, \theta_{i})$。由于方程（\ref{eq:4-26}）中定义的后验分布是难以处理的，该算法提出了一种类似期望传播的算法[41]来近似后验。

\section{个性化技术的基准}
在这一节中，我们回顾了适合作为联合学习中每个人标准化方法的基准的数据集。我们考虑的是具有非IID方数据分布的数据集，即每一方的数据是从不同的分布中取样的。我们回顾了先前工作中使用的数据集，以及其他可能适合个性化问题设置的数据集。

大体上分类，该领域的先前工作使用了以下类型的数据集之一：（a）合成数据集，其中定义了数据集的生成过程，以生成各方的数据样本；（b）通过根据一些假设对常用的数据集（如MNIST或CIFAR-10[32]）进行分区，模拟联合数据集；以及（c）利用具有自然分区的数据集，如从多方收集的数据。我们现在详细研究一下这些类型中的每一种。

\subsection{合成的联合数据集}
一个相当常见的生成合成联合数据集的方法是遵循Shamir等人[49]提出的方法，并添加了一些修改以注入各方的异质性。虽然所提出的方法之间生成数据集的确切方式不同，但基本过程如下：对于每个设备$k$，根据模型$y = \arg \max(\text{softmax}(\bm{W}x+ b))$生成样本（$\bm{X}_{k}, \bm{Y}_{k}$）。模型参数$\bm{W}_{k}$和$b_{k}$由参数$\alpha$控制，采样方式为：$u_{k} \sim \mathcal{N}(0, \alpha), \bm{W}_{k} \sim \mathcal{N}(u_{k}, 1), b_{k} \sim \mathcal{N}(u_{k}, 1)$。$\bm{X}_{k}$的生成由第二个参数$\beta$控制，其采样方式为： $\bm{B}_{k} \sim \mathcal{N}(0, \beta), v_{k} \sim \mathcal{C}(\bm{B}_{k}, 1)$, $\sum$是一个对角线协方差矩阵，$\sum_{j, j} = j^{-1, 2}$,和$x_{k} \sim \mathcal{N}(v_{k}, \sum)$。

这个合成数据集$\text{Synthetic}(\alpha, \beta)$有两个参数：$\alpha$和$\beta$。这里，$\alpha$控制本地模型之间的差异程度，$\beta$控制每个设备上的本地数据与其他方的数据的差异程度。

\subsection{模拟联合数据集}
模拟联合数据集的一个常见方法是使用常用的数据集，并根据一个假设在各方之间进行划分。之前的工作一般利用MNIST,2CIFAR-10和CIFAR-100[32]等数据集来完成这一任务。由于这些数据集没有特定的自然特征可用于在各方之间进行划分，我们需要根据假设对其进行划分。 一种分区方式是对每一方的数据点从特定的类子集中抽样，以确保各方不会看到来自所有类的数据，从而没有代表数据集中所有类的特征。另一种分区方式包括使用数据样本在各方之间的概率分配--如抽样$p_{k} \sim \text{Dir}_{N}(\alpha)$，并将$p_{k, i}$比例的$k$类实例分配给$i$方[64]。

合成的联合数据集的优点是可以控制数据集中的异质性数量；但是，它们受限于所能支持的各方数量。以前的工作都是以几十人的数量来进行实验的。虽然这适合于企业环境中的联合学习，因为在企业环境中，各方的数量通常不会有太大的变化，但这种设置并没有考虑到在智能手机或物联网类型的应用中通常遇到的规模。

\subsection{公共联合数据集}
除了合成和模拟的联合数据集，还有一些数据集，它们支持各方之间的数据自然分割。LEAF[6]是一个流行的联合学习方法的基准，它为图像分类、语言建模和情感分析任务提供多个数据集。这些数据集由于接近现实生活中的非IID数据特征，以及它们所支持的各方规模，因此是衡量个性化技术的首选数据集。LEAF中包含的一些数据集是：
\begin{itemize}
	\item \textbf{FEMNIST}： Extended MNIST（EMNIST）[13]是一个包含数字、大写和小写字符的手写样本的数据集，总共有62个类标签。EMNIST数据集被手写样本的原始写作者划分为3,500多方，以创建FEMNIST数据集。
	\item \textbf{Shakespeare数据集}： 该数据集用于语言建模任务，是根据《威廉-莎士比亚全集》3建立的，将每部戏剧中的每个说话的角色视为一个单独的当事人。
\end{itemize}

关于LEAF中可用的数据集及其总量和政党层面的统计数据的详情，可在表4.2中找到。

除了LEAF中提供的数据集，还有其他一些数据集也具有联合学习任务中个性化所需的特征。这些数据集中的一些是：

\begin{itemize}
	\item \textbf{Google Landmarks Dataset v2 (GLDv2)}：GLDv24是一个大规模的细粒度数据集，用于实例识别和图像检索任务[60]。它由246个国家的大约500万张人造和自然地标的图像组成，这些图像有大约20万个不同的标签。这个数据集可以通过根据地标的地理位置或者是地标的位置来划分，从而在联合学习环境中得到利用，或地标类别，或作者。鉴于其规模和多样性，这个数据集是个性化任务的一个强有力的测试平台。
	\item \textbf{MIMIC-III}：Medical Information Mart for Intensive Care III (MIMIC-III) [30]是一个大规模的去识别的健康相关数据，包括2001年至2012年期间在马萨诸塞州波士顿一家医院的重症监护室住院的4万多名患者。它包括超过60,000名重症监护室住院患者的人口统计学、生命体征测量、实验室测试结果、程序、药物、护理人员记录、成像报告和死亡率（包括院内和院外）等信息。虽然这个数据集的规模与GLDv2相比是有限的，但它是最大的可用医疗数据集之一，因此为评估联合学习的个性化提供了一个重要的基准。
\end{itemize}

\section{个性化是附带的参数问题}
对于联合学习中的个性化限制，有一个可能的理论解释：附带参数问题。我们考虑联合学习中个性化的一般模型：聚合者和各方的目标是解决一个优化问题，其形式为
\begin{align}\label{eq:4-27}
	\min_{\theta, \theta_{1}, \cdots, \theta_{N}} \frac{1}{N} \sum_{i=1}^{N} \mathcal{L}_{i}(\theta, \theta_{i})
\end{align}
其中，θ是共享的模型参数，θi是特定政党的参数，Li是第i个政党的经验风险。在大多数联合学习的设置中，每一方的样本量是有限的，所以对特定政党的参数θia的估计只能达到一定的精度，而这个精度取决于每一方的样本量。我们可能希望有可能更准确地估计共享参数θ，但这只在一定程度上是可能的。

该问题的人口版本是
\begin{align}\label{eq:4-28}
	\min_{\theta, \theta_{1}, \cdots, \theta_{N}} \frac{1}{N} \sum_{i=1}^{N} \mathcal{R}_{i}(\theta, \theta_{i})
\end{align}
其中$\mathcal{R}_{i}$是第$i$方的（人口）风险： $\mathcal{R}_{i}(\cdot) = E[\mathcal{L}_{i}(\cdot)]$。让$(\hat{\theta}, \hat{\theta}_{1}, \cdots, \hat{\theta}_{N})$和$(\theta^{*}, \theta_{1}^{*}, \cdots, \theta_{N}^{*})$分别为(4.27)和(4.28)的argmin。共享参数的估计值满足得分方程：
\begin{align}
	0 = \frac{1}{N} \sum_{i=1}^{N} \partial{\theta} \mathcal{L}_{i}(\hat{\theta}, \hat{\theta}_{1}, \cdots, \hat{\theta}_{N})
\end{align}
围绕$(\theta^{*}, \theta_{1}^{*}, \cdots, \theta_{N}^{*})$展开得分方程（并放弃高阶项），我们有
\begin{align*}
	0 = \frac{1}{N} \sum_{i=1}^{N} \partial_{\theta} \mathcal{L}_{i}(\theta^{*}, \theta_{1}^{*}, \cdots, \theta_{N}^{*}) + \partial_{\theta}^{2} \mathcal{L}_{i}(\theta^{*}, \theta_{1}^{*}, \cdots, \theta_{N}^{*})(\hat{\theta} - \theta^{*}) \\
	+ \partial_{\theta_{i}}\partial_{\theta} \mathcal{L}_{i} (\theta^{*}, \theta_{1}^{*}, \cdots, \theta_{N}^{*})(\hat{\theta} - \theta^{*})
\end{align*}
我们重新排列以隔离共享参数的估计误差
\begin{align*}
	\hat{\theta} - \theta^{*} = (\frac{1}{N} \sum_{i=1}^{n} \partial_{\theta}^{2} \mathcal{L}_{i}(\theta^{*}, \theta_{1}^{*}, \cdots, \theta_{N}^{*}))^{-1} (\frac{1}{N} \sum_{i=1}^{N} \partial_{\theta} \mathcal{L}_{i}(\theta^{*}, \theta_{1}^{*}, \cdots, \theta_{N}^{*}) \\
	+ \partial_{\theta_{i}}\partial_{\theta} \mathcal{L}_{i} (\theta^{*}, \theta_{1}^{*}, \cdots, \theta_{N}^{*})(\hat{\theta} - \theta^{*}))
\end{align*}
我们看到，政党特定参数的估计误差通过$\partial_{\theta_{i}}\partial_{\theta} \mathcal{L}_{i}(\theta^{*}, \theta_{1}^{*}, \cdots, \theta_{N}^{*})(\hat{\theta}_{i} - \theta_{i}^{*})$的平均值影响共享参数的估计误差。这个平均数通常不是平均值为零，因此，即使各方的数量增加，它也不会收敛为零。要使这个平均值收敛为零，必须发生以下两种情况之一：
\begin{enumerate}
	\item $\hat{\theta}_{i} - \theta_{i}^{*} \rightarrow^{p} 0$：个性化参数的估计误差收敛为零。只有当每一方的样本量增加时，这才有可能。不幸的是，在大多数联合学习问题中，各方的计算和存储限制排除了这种情况。
	\item $\partial_{\theta_{i}}\partial_{\theta} \mathcal{L}_{i}(\theta^{*}, \theta_{1}^{*}, \cdots, \theta_{N}^{*})$为均值零。这相当于分数方程（4.29）满足某种正交性属性[12，42]。如果分数方程满足这一属性，那么特定政党参数的估计误差就不会影响（一阶）共享参数的估计。尽管这是非常理想的，但正交性只发生在某些特殊情况下。
\end{enumerate}

综上所述，共享参数的估计误差通常受到党派特定参数的估计误差的影响，而且在现实的联合学习环境中，它不会收敛为零，在这种情况下，党派的数量会增加，但每个党派的样本量仍然是有限制的。退一步讲，从自由度的角度来看，这也是可以预期的。随着各方数量的增加，虽然总样本量增加，但我们必须学习的参数总数也会增加。换句话说，联合学习中的个性化是一个高维度的问题。众所周知，这样的问题是具有挑战性的，除非参数表现出特殊的结构（如稀疏性、低等级），否则估计误差一般不会收敛为零。不幸的是，在联合学习中通常不是这种情况。

实际上，这意味着如果我们在联合学习问题中加入了个性化，那么在不增加每一方的样本量的情况下，增加一方的数量超过一定程度就是暴殄天物。我们是否超过了这一点，可以通过检查共享参数估计的质量是否随着更多的缔约方的加入而提高来确定。如果我们超过了这一点，那么特定政党参数的估计误差就会支配共享参数的估计误差，所以参数共享就没有好处。这就是所谓的附带参数问题，它在统计学中有着悠久的历史。我们可以参考[33]对该问题的回顾。

\section{总结}
在这一章中，我们通过证明原生的联合学习与他们在本地训练模型相比，不一定能帮助所有各方训练出更好的模型来激发个性化的需求。为了缓解这个问题，人们提出了不同的个性化技术。我们根据这些技术所采用的个性化策略的类型，将其分为八大类。除了对个性化策略的回顾之外，我们还对联合学习中的个性化的统计挑战进行了概述。在本章的最后，我们提供了在实施或利用个性化策略时需要考虑的实际问题的建议，以及未来的研究方向和对联合学习中的个性化理论理解的开放问题。

\textbf{实际考虑。}为你的应用选择一个个性化的策略，与参与联合学习设置的各方和聚合器的属性密切相关。具体来说，有助于做出明智选择的问题是： (1) 所有各方都有相同的模型架构吗？(2) 是否有一个数据共享机制可以用来增加本地数据？(3) 参与方和聚合器的计算能力如何？ (4) 你希望每一方有多少数据？

如果不是所有各方都有相同的模型架构，或者最好是不同各方有不同的架构，那么应该探索基于蒸馏的方法（第 4.3.4 节）或 LG-FedAvg [35] 方法。这些技术支持并已被实验证明可以与不同的当事方和全局模型架构一起工作。另一个重要的考虑因素是是否有可用的全局数据来增强本地数据。虽然共享聚会数据违反了联合学习的核心原则，但如果有可能收集到一个共享的数据集，用于个性化的数据增强技术（第4.3.3节）可以成为这些场景中强有力的候选者。

当事人和聚合者的计算能力在选择个性化策略方面也起着重要作用。具体到当事人，如果计算能力和内存能力充足，那么可以探索混合模型的方法（第4.3.6节）。由于混合模型的方法在各方身上保持了一个局部和一个全局模型，并使用两者的组合进行推理，它大大增加了参与各方的内存和计算要求。按照类似的思路，如果聚合器有足够的内存容量，允许维护多个模型参数，那么客户（方）聚类方法（第4.3.1节）可能会有帮助。

有助于做出明智决定的最后一个问题是关于每一方的可用数据量。这是应用情境化方法的一个重要考虑。客户端（当事方）情境化（第4.3.2节）增加了从本地数据中学习的参数数量，如果当事方有足够的数据，那么就有可能学习这些情境参数来帮助实现个性化。

最后，无论上述条件是否满足，元学习（第4.3.5节）和模型正则化（第4.3.7节）方法都适用，在选择个性化策略时应始终考虑。

\textbf{推进联合学习中的个性化。}随着文献中提出的个性化算法越来越多，我们认为下一个重要的步骤是建立基准和性能指标，以有效和可靠地衡量所提出的技术的性能。这需要有模仿实际部署中通常遇到的情况的数据集。虽然有一些数据集可用于这一目的，但需要在更广泛的应用领域提供更多的数据集。在标准化的数据集上进行基准测试，可以更好地解释所提出的技术的能力和局限性，也可以方便地比较各种技术。除了数据集之外，还需要一个标准化的个性化评估设置。评价联合学习技术的典型方法是测量全局模型的性能，这种技术也被移植到了个性化问题上。然而，正如我们在个性化的激励性例子中所看到的，测量全局模型的准确性并不一定能提供对每一方性能的完整描述。因此，定义一个考虑到每一方性能的评估设置将成为有效评估个性化技术的一个重要贡献。

\textbf{对个性化的理论理解。}正如我们所看到的，由于偶然的参数问题，个性化存在着一个可扩展性问题。这个问题因其统计学性质而与机器学习中的大多数可扩展性问题相区别。克服这个问题是将个性化扩展到大型聚会云的一个要求。不幸的是，一个世纪以来，统计学界一直没有找到解决底层偶然参数问题的一般方法，所以不太可能有一般的方法来进行大规模的个性化定制。然而，也许有可能开发出针对特定模型的解决方案

\bibliographystyle{unsrtnat}
\bibliography{ref_fl}