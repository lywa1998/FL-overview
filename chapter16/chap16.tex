\chapter{联邦学习在医学影像中的应用}

\section{摘要}
人工智能，特别是深度学习在医学成像领域显示出巨大的潜力。这些模型可用于分析放射学/病理图像来协助医生完成临床工作流程中的任务，如疾病检测、医疗干预、治疗计划和预后等等。准确和可归纳的深度学习模型需求量很大，但需要大量和多样化的数据集。医学图像的多样性意味着在不同机构收集的图像，使用多种设备和参数设置，来自不同的病人群体。因此，制作一个多样化的医学图像数据集需要多个机构共享他们的数据。尽管医学数字成像和通信（DICOM）作为一种通用的图像存储格式已被普遍接受，但多个机构之间共享大量的医学图像仍然是一个挑战。主要原因之一是对包括医疗图像在内的个人可识别健康数据的存储和共享有严格规定。目前，大量的数据集通常是在少数机构的参与下，经过严格的去识别，从医学图像和病人健康记录中去除个人可识别的数据。去除身份识别很耗时、很昂贵、很容易出错，在某些情况下还会删除有用的信息。联合学习的出现是一个实用的解决方案，可以使用大型的多机构数据集训练人工智能模型，而不需要共享数据，从而消除了去识别的需要，同时满足了必要的法规。在本章中，我们介绍了几个使用IBM联合学习的医学成像的例子。

\section{导言}
随着深度学习的出现，计算机视觉算法有了很大的飞跃。预计在医疗图像的计算机视觉领域也会有类似的进展。将计算机视觉任务（如检测、分割和分类）应用于医学图像，对协助医生更快、更准确、更稳定地完成任务有极大帮助。许多任务，如疾病检测、肿瘤定位、治疗计划和预后等，都可以从深度学习模型中获益（见[1]和其中的参考文献）。然而，为了训练准确、可靠和可推广的深度学习模型，人们需要来自不同来源的大量训练样本数据集。虽然在公共领域可以轻易获得大量不同的自然图像集[2]，但公开可用的医学成像数据集相对较少，且来源有限[3，4]。缺乏这种大型和多样化的训练数据集有两个主要原因：（1）对标签和注释的要求，以及（2）健康数据共享的困难。

为了进行有监督的训练，人们需要对图像进行标签或注释。通过众包获得自然图像的标签是相对容易和便宜的。然而，在医学领域，标签和注释应该由医学专家制作。最近，自然语言处理（NLP）方法被用来分析放射学报告并大规模地自动生成标签[5, 6]。然而，如果需要详细的注释，如器官或肿瘤周围的轮廓，注释任务会变得非常昂贵。目前正在开发自我监督和无监督的学习方法，以训练模型，减少对注释数据的依赖，克服第一个障碍。

尽管全世界都接受了医学数字成像和通信（DICOM）格式，但在多个机构之间共享医学图像仍然是一个挑战[7]。这一挑战的主要原因是，医学图像和其他健康记录一样，可能包含受保护的健康信息（PHI），并受到法律法规的严格保护，如美国的《健康保险可携带性和责任法案》（HIPAA）[8]或欧洲的《一般数据保护条例》（GDPR）[9]。因此，共享医疗图像需要严格的去识别。解除身份识别很耗时、很昂贵、很容易出错，在某些情况下还会删除有用的信息。

联合学习是一种机器学习技术，它允许几方参与模型训练而不分享他们的本地敏感数据[10]。在联合学习的情况下，每个训练方使用其本地数据训练一个模型，并将其模型更新，而不是训练数据，发送给一个聚合器，该聚合器将来自不同方的更新合并为一个单一的模型（见图22.1）。联合学习允许我们使用大量不同的数据集来训练可归纳的模型，同时通过避免分享敏感数据来满足安全和隐私法规。因此，联合学习对医学成像来说是一个非常有吸引力的解决方案。

在这一章中，我们展示了医学成像中两个最常见的计算机视觉应用的实现：图像分类和图像分割。在第一项任务中，根据目标图像结论集合的存在与否，将图像分为正片或负片。在第二项任务中，该模型产生一个二进制掩码，划定一个目标对象。

我们使用IBM Federated Learning[11]训练我们的模型，它为联合学习提供了基础设施和协调。虽然这个框架适用于深度学习模型以及其他机器学习方法，但我们严格使用它来训练深度学习模型。

在下面的章节中，我们展示了联合学习在上述两项任务中的应用。我们报告了我们在图像分割方面的工作，以划定容积CT图像中的肺部栓塞。我们还进行了二维和三维图像分类的实验，通过训练模型来检测X光图像中的气胸和三维CT图像中的肺气肿。对于图像分割和三维图像分类，我们实施了一个模拟的联合学习场景。在这种情况下，训练数据被记录在一个集中的存储库中，但它被分割成不同的组，每组数据由一方专门用于训练模型。由于数据被保存在一个集中的地方，训练后的模型可以与集中训练的模型进行比较。然而，对于二维分类任务，我们使用了保存在两个地理上相距甚远的存储库中的两个数据源来展示一个更现实的场景。

\section{图像分割}
勾勒器官、异常或其他图像结果是计算机视觉在医学成像中的主要应用之一。为了证明联合学习在此类任务中的能力，我们实施了一个分割模型来勾勒对比度增强的胸部CT图像中的肺栓塞。肺栓塞（PE）是肺动脉的阻塞，很可能是由血凝块引起的。CT肺动脉造影（CTPA）是检测PE的首选成像方式。检测临床上明显的PE对于快速诊断有静脉血栓栓塞症状和体征的患者非常重要。未经治疗的临床明显的PE有近$30\%$的死亡率，而那些接受治疗的患者的死亡率为$8\%$[12-16]。虽然单纯PE的死亡率只有$2.5\%$[17]，但及时发现和抗凝治疗可以改善患者的预后。建议疑似PE的患者进行D-二聚体检测，然后进行CT肺血管造影（CTPA），进行高概率的临床评估。放射科医生必须仔细检查疑似PE的肺动脉的每个分支。因此，PE的诊断取决于放射科医生的经验、注意力和眼睛的疲劳程度等。历史上，用于检测PE的计算机辅助检测（CAD）软件已被证明可以帮助放射科医生检测和诊断PE[18-22]。此外，在CT血管造影（CTA）图像中检测PE在回顾性设置中是有用的，CAD软件被用来检测遗漏的结果。

PE通常具有小尺寸的不规则形状的病理模式。因此，即使使用图像补丁，对PE分类有特色的图像区域可能只占成像数据的一小部分。定位独特的图像区域是成功进行PE分类的关键。已经开发了计算机辅助方法来自动检测PE。这些方法通常是两阶段的解决方案，第一阶段在图像中产生一组PE候选者，第二阶段将候选者分类为真PE和假阳性[23-25]。第一阶段可以实现为一个分割任务，其中一个模型分析图像并划出候选栓子，由第二阶段进行分类。

在本节中，我们在联合设置中使用2个数据集来训练一个PE分割模型作为第一阶段。第一个数据集[26]由40张CTPA图像组成，每张图像来自不同的病人。这些扫描是在西班牙马德里的Unidad Central de Radiodiag- nóstico获得的，使用当地机构的CTPA协议从几台扫描仪上获得。每个CTPA容积都由三位具有多年经验的委员会认证的放射科医生独立进行注释，最后通过合并所有三个注释创建一个参考标准。我们在第一方使用这个数据集。第二个数据集[27]包括由伊朗马什哈德Ferdowsi大学发表的35名不同患者的肺栓塞的计算机断层扫描血管图（CTA）图像。每张CTA图像都由两位放射科医生进行注释，并进行整合，以建立一个参考标准。我们在第二方使用这个数据集。

为了进行测试，我们使用了一个私人数据集，其中包括从多家扫描仪和医院获得的334个容积，包括CTA和CTPA容积。为了注释每个PE阳性的容积，一个由7名委员会认证的放射学专家组成的小组在间隔约10毫米的切片上围绕每个栓塞画了一条轮廓。注释者的任务是不重叠的，因此每个CT容积只由一个注释者进行注释。

为了更有效地检测，我们应用PE分割法来识别栓塞候选者。为了给注释的切片提供更多的背景，我们使用U-Net[28]的基于板块的2D分割方法。不仅仅是使用二维切片，而是将九个切片的板块输入网络，并将相应的二进制掩码作为基础事实。在我们的分割任务中，U-Net模型由70层组成，收缩路径是重复的3×3卷积，每个卷积后都有一个整流线性单元（ReLU）和一个2×2的最大池化操作，跨度为2，用于向下采样。扩张路径包括对特征进行上采样，然后进行2×2卷积，与来自收缩路径的相应裁剪的特征图相连接，并进行3×3卷积，每个卷积后面都有一个ReLU。概率图是通过对最终的特征图进行像素级的softmax计算的。在训练中，使用了连续骰子损失（DL）函数[29]。

对于联合训练，我们由双方对上述网络进行了10轮训练，每轮50个历时。我们使用联合平均法[10]来汇总每一方的模型更新。为了比较，我们还使用合并的数据集训练了100个历时的分割模型，在我们的测试集上达到了0.45的骰子系数。每一轮结束后，我们使用测试数据集对聚合模型进行评估。在图22.2中，我们将每轮之后的聚合模型的结果与集中训练的模型的结果进行了比较。值得注意的是，聚合模型在短短5轮后就能达到与中心模型相似的性能。

\section{3D图像分类}
在本节中，我们使用联合学习来训练一个分类器，以检测三维胸部CT扫描中的肺气肿。与估计密集的二进制掩码以显示疾病的局部存在的分割不同，分类只需要在每个三维体积上得到一个二进制检测结果。 每个三维体积的单一二进制检测结果。训练时，这就转化为对每个体积的单一疾病检测的标签要求，这比分割的密集三维掩码的负担要小得多。对于训练数据的标注，它也为利用病人医疗记录中的疾病诊断代码和成像放射学报告的NLP提供了可能性。现在让我们来探讨肺气肿的疾病分类。

肺气肿是一种肺部疾病，肺泡--呼吸道末端的腔室--塌陷并合并，在肺部留下开放的空气空间区域。在CT扫描中，这表现为低衰减的黑暗斑块。计算机辅助检测肺气肿所面临的挑战是，低衰减区域可能仍有各种表现，肺气肿病变可能只出现在肺部的一部分体积中。最近，研究人员将机器学习方法用于肺气肿检测和量化，如多实例学习[30-33]、卷积神经网络（CNN）[34-36]和卷积长短时记忆（ConvLSTM）[37]。

我们的分类器的结构是基于ConvLSTM[38]，取自我们以前关于肺气肿检测的工作[37]。该架构是流行的LSTM模型的变体，利用卷积运算来区分空间模式的变化。例如，ConvLSTM在检测时空模式方面表现出色，如视频分类。我们没有将ConvLSTM应用于时间序列图像数据，而是建议使用它来扫描成像体积的一系列连续切片，以学习疾病的模式，而不需要手动注释其位置。我们的方法允许检测切片上和切片之间的疾病，通过多次双向通过一个容积来存储它们，并将其作为描述整体疾病存在的最终特征集输出。

我们的架构，如图22.3所示，由四个单元组成。每个单元有两个二维卷积层，分别从每个切片中提取特征，然后进行最大集合，最后由ConvLSTM层逐片处理体积。每个卷积层的核大小为3×3和整流线性单元（ReLU）激活，然后进行批量归一化。然后，每个切片的卷积层的输出被ConvLSTM层依次处理，有tanh激活和hard sigmoid递归激活。一个单元内的所有层共享相同数量的过滤器，并按升序或降序处理体积。这四个单元的维度和方向性如下。升序单元1：32个滤波器，降序单元1：32个滤波器，升序单元2：64个滤波器，降序单元2：64个滤波器。最后的ConvLSTM层输出一组特征，它总结了网络在多次处理成像体积后的发现。然后，一个具有乙型激活的全连接层计算出肺气肿的概率。

我们使用一个模拟的2方配置，以联合的方式训练我们的肺气肿检测网络。对于训练数据，我们的图像来自于从我们的数据提供伙伴处收集的大量CT扫描。我们将一组2035张CT扫描图分给了2方--第1方为018张，第2方为1017张，每方的正面和负面例子大致上是平均分配的（见表22.1）。对于测试数据，我们使用了相同的数据源，形成了984个CT扫描的测试队列，其中有465个负数和519个正数。为了将数据标记为肺气肿的阳性或阴性，我们利用了相关的成像报告。为了检测报告中的肺气肿，我们搜索了肺气肿这个词及其同义词的列表。这些结果都是经过人工验证的。

该模型最初以集中的方式进行训练，使用来自国家肺部筛查试验（NLST）[39]数据集的一组低剂量CT扫描，其中7100张扫描用于训练，1776张用于验证。低剂量CT扫描更适合于筛查目的，与常规剂量CT相比，受试者暴露于较低的辐射水平。为了帮助将该模型推广到常规剂量的CT扫描，我们接下来使用来自肺组织研究联盟（LTRC）[40]数据集的一组CT扫描来进行迁移学习，其中有858个训练扫描和200个验证扫描。我们用这个模型的权重作为联合学习的初始权重。

为了证明联合学习，我们对第1方和第2方的不同配置进行了一些实验，并与集中式训练进行了比较。为了比较这些模型，我们使用我们的测试集计算接受者操作特征曲线下的面积（AUC）。首先，我们在每一方独立地训练模型，从NLST的初始模型开始，训练5个历时。轮，图22.4中报告了最大的AUC。最后，为了与第1和第2方的合并训练集上的集中学习进行比较，我们以标准的集中方式训练模型，得到图22.4（右）中的测试集AUC。
我们还在测试集上测试了初始模型，如图22.4所示。

可以看出，在联合设置中训练的模型优于每个单独训练的模型，并显示出更好的泛化能力。尽管这种差异可能是由随机梯度下降的随机性以及集中训练中的历时数和联合学习场景中的有效历时数之间的差异造成的，但它也在仅仅5轮之后就略胜于集中训练的模型。

\section{2D图像分类}

\section{讨论}

\section{结论和未来工作}
