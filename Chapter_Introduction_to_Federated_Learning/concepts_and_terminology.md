# 1.2 概念和术语

在本章的其余部分，我们将对FL进行概述。我们在下一节中对所使用的主要概念进行了正式介绍。之后，我们从三个重要的角度讨论FL，每个角度都有一个单独的章节。首先，我们从机器学习的角度讨论FL；然后，我们通过概述威胁和缓解技术来涵盖安全和隐私的角度；最后，我们对联合学习的系统角度进行了概述。这将为本书的其余部分提供一个起点。

图1.2显示了FL过程是如何在这个抽象层面上进行的。为了训练一个全局机器学习模型M，聚合器和各方执行一个联合学习算法，该算法以分布式方式在聚合器上执行和各方。主要的算法组件是每一方的本地训练函数L，它在数据集Dk上进行本地训练，以及聚合器的融合函数F，它将每一方的L的结果合并为一个新的联合模型。可以有一组本地训练和融合的迭代，我们称之为轮次，使用索引t。算法的执行通过在各方和聚合器之间发送消息来协调。整个过程运行如下。

这个过程从聚合器开始。为了训练模型，聚合器使用一个函数Q，该函数将上一轮训练Mt-1的模型作为输入，并为当前回合生成一个查询qt。当这个过程开始时，M0可能是空的或只是随机的种子。另外，一些FL算法可能包括Q的额外输入，并可能为每一方定制查询，但为了讨论的简单性，在不损失一般性的情况下，我们使用这种更简单的方法。

查询qt被发送到各方，并要求提供关于他们各自的本地模型的信息或关于各方数据集的汇总信息。查询的例子包括对神经网络梯度或模型权重的请求，或对决策树计数的请求。

当收到qt时，本地训练过程执行本地训练函数L，该函数将查询qt和本地数据集Dk作为输入，并输出模型更新rk,t。通常情况下，查询qt包含了一方可以用来初始化本地训练过程的信息。例如，这包括新的共同模型Mt的模型权重，以初始化本地训练，或不同模型类型的其他信息。

当L完成后，Rk,t从pk方发回给聚合器A，后者收集所有各方的Rk,t。

当聚合器收到所有预期各方的模型更新Rt= (r1,t, r2,t, ... , rn,t)时，它们被应用融合函数F进行处理，该函数将Rt作为输入并返回Mt。

这个过程可以在多轮中执行，并持续到满足终止标准为止，例如，最大的训练轮数tmax已经过去，最终形成一个全局模型M = Mtmax。所需的训练轮数可以有很大的不同，从Naive Bayes方法的单一模型合并到典型的基于梯度的机器学习算法的多轮训练。

本地训练函数L，融合函数F，和查询生成函数Q通常是一个互补的集合，被设计为共同工作。
L与实际数据集交互，进行局部训练，生成模型更新Rk,t。Rt的内容是F的输入，因此，必须由F来解释，它根据这个输入创建下一个模型Mto。如果需要另一个回合，Q就会创建另一个查询。

在接下来的章节中，我们将详细描述这一过程在训练神经网络、决策树和梯度增强树的情况下是如何发生的。

我们可以为FL的这一基本方法引入不同的变体。在跨设备FL的情况下，各方的数量往往很大，达到数百万。并非所有各方参与每一轮。在这种情况下，Q不仅决定了查询，还决定了在下一轮查询中包括哪些政党Ps⊂P。党派的选择可以是随机的，基于党派的特征，或基于先前贡献的优点。

另外，对每一方的查询可能是不同的，F需要在创建一个新的模型Mt时整合不同查询的结果。

虽然有一个单一的聚合器的方法是最常用的，而且对大多数情况下是实用的，但也有人提出了其他的FL架构。例如，每一方Pkm可能有它自己的、相关的聚合器Ak，查询其他各方；各方的集合可能在聚合器之间被分割，并且可能发生一个分层的聚合过程。在介绍的其余部分中，我们重点讨论常见的单一聚合器配置。